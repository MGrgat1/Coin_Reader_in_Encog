{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2k9lN7lmtsEDYI7+urgPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MGrgat1/Coin_Reader_in_Encog/blob/master/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1 - data loader"
      ],
      "metadata": {
        "id": "nn9U9Xo1pATO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZGVLiOoWd7H"
      },
      "outputs": [],
      "source": [
        "# U ovom primjeru radit ćemo s MNIST setom podataka kako treniranje ne bi predugo trajalo\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "# Skinemo podatke MNIST dataseta kao u četvrtom predavanju\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "# Koristimo dataloader za uzimanje podataka iz setova podataka:\n",
        "# Označavamo veličinu batch_size-a i treba li podatke izmješati (shuffle)\n",
        "# Batch size jednostavno mjenjamo kasnije ukoliko je kod dobro napisan!\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "# Ispisuje sljedeće:\n",
        "# torch.Size([64, 1, 28, 28])\n",
        "# torch.Size([64])\n",
        "# Zašto?\n",
        "# Zato što imamo 64 slikice u batch-u, slika ima jedan kanal (Greyscale) i velika je 28 x 28 piksela\n",
        "# Postoji jedan label za jednu sliku (kategoriju) i imamo 64 slike i samim time 64 kategorije\n",
        "\n",
        "#Prikažimo slike... Onako usput.\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.title(str(labels.numpy()[index]))\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Example 2 - NN GPU"
      ],
      "metadata": {
        "id": "rDmX8GRRpJM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# U ovom primjeru radit ćemo s MNIST setom podataka kako treniranje ne bi predugo trajalo\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "# Skinemo podatke MNIST dataseta kao u četvrtom predavanju\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "# Koristimo dataloader za uzimanje podataka iz setova podataka:\n",
        "# Označavamo veličinu batch_size-a i treba li podatke izmješati (shuffle)\n",
        "# Batch size jednostavno mjenjamo kasnije ukoliko je kod dobro napisan!\n",
        "# pin_memory znači loading u GPU. Neće raditi ako nema više workera!\n",
        "train_loader = DataLoader(trainset, batch_size=1024, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=1024, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "# Kreiramo model:\n",
        "# Ulaz je 784. Zašto? Zato što je 28 x 28 = 784\n",
        "# Dakle, za svaki piksel imamo jedan ulaz u NN.\n",
        "# Hidden veličine su nasumične\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "output_size = 10\n",
        "\n",
        "# Prvo imamo linearni sloj, pa aktivaciju, pa linearni sloj itd...\n",
        "# Na kraju dodajemo softmax koji se standardno koristi prilikom klasifikacije.\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Bilježimo početak\n",
        "time0 = time()\n",
        "# Idemo trenirati 15 epoha\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        # Sjetimo se što radi ova komanda!\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "\n",
        "        # Nuliramo gradijente\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Tražimo izlaz iz mreže i računamo grešku\n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels.to(device))\n",
        "\n",
        "        # Propagiramo grešku unazad\n",
        "        loss.backward()\n",
        "\n",
        "        # Idemo na idući korak\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss / len(train_loader)))\n",
        "print(\"\\nTrenirali smo (u minutama):\", (time() - time0) / 60)\n"
      ],
      "metadata": {
        "id": "w2s9FUMXpa2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3 - testing\n"
      ],
      "metadata": {
        "id": "Kdic_5KtpdbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss / len(train_loader)))\n",
        "print(\"\\nTrenirali smo (u minutama):\", (time() - time0) / 60)\n",
        "\n",
        "# Poigrajte se samo s veličinom batch-a ;)\n",
        "# Proučite kakav efekt ima veličina batch-size-a na treniranje!\n",
        "# Krenite od: https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e\n",
        "correct_count, all_count = 0, 0\n",
        "for images, labels in test_loader:\n",
        "    for i in range(len(labels)):\n",
        "        img = images[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "            logps = model(img.to(device))\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.cpu().numpy()[i]\n",
        "        if (true_label == pred_label):\n",
        "            correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "print(\"Broj testiranih slika =\", all_count)\n",
        "print(\"\\nTočnost modela =\", (correct_count / all_count))"
      ],
      "metadata": {
        "id": "tR3htpsQplsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4 - storage GPU"
      ],
      "metadata": {
        "id": "4MR1EZ58plB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=256, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "output_size = 10\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 3\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss / len(train_loader)))\n",
        "print(\"\\nTrenirali smo (u minutama):\", (time() - time0) / 60)\n",
        "\n",
        "torch.save(model, 'models/moj_model_gpu.pth')\n",
        "\n",
        "loaded_model = torch.load('models/moj_model_gpu.pth')\n",
        "print(model)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'models/moj_model_gpu_stateovi.pth')\n",
        "\n",
        "model_load = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "model_load.load_state_dict(torch.load('models/moj_model_gpu_stateovi.pth'))\n",
        "model_load.to(device)\n",
        "\n",
        "print(model_load)\n",
        "# Dakle, pohrana je jako slična kada radimo s jednim GPU-om!\n",
        "# U slučaju korištenja više GPU-ova, slučaj je malo drugačiji jer se koristi DataParallel model\n",
        "# no to ćemo raditi na naprednim tehnikama treniranja."
      ],
      "metadata": {
        "id": "U8Gc18p-prid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Example 5 - training with progress bar (tqdm)"
      ],
      "metadata": {
        "id": "rWWwIYswpw1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time, sleep\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "output_size = 10\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    # sjetimo se čemu služi enumerate!\n",
        "    #Kreiramo petlju pomoću tqdm poziva. Kažemo mu ukupnu duljinu dataseta kako bi znao točno gdje smo.\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
        "    #Sada tu imamo i index zbog enumerate\n",
        "    for idx, (images, labels) in loop:\n",
        "\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        labels = labels.to(device)\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Idemo odmah napraviti prikazivanje točnosti :)\n",
        "        predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
        "        correct = (predictions == labels).sum().item()\n",
        "        accuracy = 100. * (correct / len(predictions))\n",
        "        loop.set_description(f\"Epoch [{e}/{epochs}\")\n",
        "        loop.set_postfix(loss = loss.item(), acc=accuracy)"
      ],
      "metadata": {
        "id": "PWa-1CIMp2p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 6 - training with tensorboard"
      ],
      "metadata": {
        "id": "rmBVQRL5p9C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time, sleep\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "import pkbar\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "batch_size = 256\n",
        "#Inicijalizacija writera\n",
        "writer = SummaryWriter('runs/MNIST')\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "output_size = 10\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "epochs = 15\n",
        "train_per_epoch = int(len(trainset) / batch_size)\n",
        "for e in range(epochs):\n",
        "    kbar = pkbar.Kbar(target=train_per_epoch, epoch=e, num_epochs=epochs, width=20, always_stateful=False)\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        labels = labels.to(device)\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        writer.add_scalar('loss', loss.item(), (e * train_per_epoch) + idx)\n",
        "        predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
        "        correct = (predictions == labels).sum().item()\n",
        "        accuracy = correct / len(predictions)\n",
        "        kbar.update(idx, values=[(\"loss\", loss), (\"acc\", accuracy)])\n",
        "        writer.add_scalar('acc', accuracy, (e * train_per_epoch) + idx)\n",
        "        # Writer ima i funkcije za dodavanje ostalih tipova podataka. Slobodno ih istražite!"
      ],
      "metadata": {
        "id": "W26LyDrbqDI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# LAB 4"
      ],
      "metadata": {
        "id": "mVC5FDo8qEmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "\n",
        "# Installs"
      ],
      "metadata": {
        "id": "ds502V1-9rr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pkbar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV3YcyCB1bHZ",
        "outputId": "e35e7f56-c845-4cec-a084-f9a916529d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pkbar\n",
            "  Downloading pkbar-0.5-py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pkbar) (1.21.6)\n",
            "Installing collected packages: pkbar\n",
            "Successfully installed pkbar-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "jiuSUxF19nDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "bAIm7OE59fnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time, sleep\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "import pkbar\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "batch_size = 256\n",
        "#Inicijalizacija writera\n",
        "writer = SummaryWriter('runs/EMNIST')\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# trainset = datasets.MNIST('mnist_data', download=True, train=True, transform=transforms)\n",
        "# testset = datasets.MNIST('mnist_data', download=True, train=False, transform=transforms)\n",
        "\n",
        "## torchvision.datasets.EMNIST(root: str, split: str, **kwargs) → None\n",
        "## root (string) – Root directory of dataset where EMNIST/processed/training.pt and EMNIST/processed/test.pt exist.\n",
        "## split (string) – The dataset has 6 different splits: byclass, bymerge, balanced, letters, digits and mnist. This argument specifies which one to use.\n",
        "## train (bool, optional) – If True, creates dataset from training.pt, otherwise from test.pt.\n",
        "## download (bool, optional) – If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n",
        "\n",
        "trainset = datasets.EMNIST('emnist_data', split='letters', download=True, train=True, transform=transforms)\n",
        "testset = datasets.EMNIST('emnist_data', split='letters', download=True, train=False, transform=transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "hidden_size_3 = 32\n",
        "output_size = 27\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, hidden_size_3),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_3, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "epochs = 15\n",
        "train_per_epoch = int(len(trainset) / batch_size)\n",
        "for e in range(epochs):\n",
        "    kbar = pkbar.Kbar(target=train_per_epoch, epoch=e, num_epochs=epochs, width=20, always_stateful=False)\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.to(device).view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        labels = labels.to(device)\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        writer.add_scalar('loss', loss.item(), (e * train_per_epoch) + idx)\n",
        "        predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
        "        correct = (predictions == labels).sum().item()\n",
        "        accuracy = correct / len(predictions)\n",
        "        kbar.update(idx, values=[(\"loss\", loss), (\"acc\", accuracy)])\n",
        "        writer.add_scalar('acc', accuracy, (e * train_per_epoch) + idx)\n",
        "        # Writer ima i funkcije za dodavanje ostalih tipova podataka. Slobodno ih istražite!"
      ],
      "metadata": {
        "id": "gk1LA-erM4gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59846ac0-63d3-4007-ad98-5f97fcf43c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487/487 [====================] - 36s 75ms/step - loss: 2.8192 - acc: 0.2065\n",
            "Epoch: 2/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 1.5025 - acc: 0.5517\n",
            "Epoch: 3/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 1.1698 - acc: 0.6539\n",
            "Epoch: 4/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.9578 - acc: 0.7163\n",
            "Epoch: 5/15\n",
            "487/487 [====================] - 35s 73ms/step - loss: 0.7998 - acc: 0.7618\n",
            "Epoch: 6/15\n",
            "487/487 [====================] - 35s 73ms/step - loss: 0.6938 - acc: 0.7928\n",
            "Epoch: 7/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.6213 - acc: 0.8125\n",
            "Epoch: 8/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.5679 - acc: 0.8280\n",
            "Epoch: 9/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.5260 - acc: 0.8397\n",
            "Epoch: 10/15\n",
            "487/487 [====================] - 37s 75ms/step - loss: 0.4917 - acc: 0.8501\n",
            "Epoch: 11/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.4657 - acc: 0.8568\n",
            "Epoch: 12/15\n",
            "487/487 [====================] - 36s 75ms/step - loss: 0.4394 - acc: 0.8647\n",
            "Epoch: 13/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.4188 - acc: 0.8709\n",
            "Epoch: 14/15\n",
            "487/487 [====================] - 35s 73ms/step - loss: 0.4016 - acc: 0.8759\n",
            "Epoch: 15/15\n",
            "487/487 [====================] - 36s 74ms/step - loss: 0.3880 - acc: 0.8793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "lnj60d599f_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Poigrajte se samo s veličinom batch-a ;)\n",
        "# Proučite kakav efekt ima veličina batch-size-a na treniranje!\n",
        "# Krenite od: https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e\n",
        "correct_count, all_count = 0, 0\n",
        "for images, labels in test_loader:\n",
        "    for i in range(len(labels)):\n",
        "        img = images[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "            logps = model(img.to(device))\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.cpu().numpy()[i]\n",
        "        if (true_label == pred_label):\n",
        "            correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "print(\"Broj testiranih slika =\", all_count)\n",
        "print(\"\\nTočnost modela =\", (correct_count / all_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1eeG4rU921S",
        "outputId": "60be414d-c520-48b2-8598-056d5824d5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broj testiranih slika = 20800\n",
            "\n",
            "Točnost modela = 0.8739423076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result analysis"
      ],
      "metadata": {
        "id": "2KRq8NXlWVhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration 1**\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "input_size = 784\n",
        "hidden_size_1 = 128\n",
        "hidden_size_2 = 64\n",
        "hidden_size_3 = 32\n",
        "output_size = 27\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, hidden_size_3),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_3, output_size),\n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "loss_fn = nn.NLLLoss().to(device)\n",
        "\n",
        "epochs = 15\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "**Training runs:**\n",
        "1. \n",
        "Epoch: 15/15\n",
        "487/487 [====================] - 37s \n",
        "77ms/step - loss: 0.3994 - acc: 0.8757\n",
        "Točnost modela = 0.8619230769230769\n",
        "\n",
        "2. \n",
        "Epoch: 15/15\n",
        "487/487 [====================] - 37s \n",
        "77ms/step - loss: 0.3878 - acc: 0.8796\n",
        "Točnost modela = 0.8679807692307693\n",
        "\n",
        "3.\n",
        "Epoch: 15/15\n",
        "487/487 [====================] - 36s \n",
        "74ms/step - loss: 0.3880 - acc: 0.8793\n",
        "Broj testiranih slika = 20800\n",
        "Točnost modela = 0.8739423076923077\n"
      ],
      "metadata": {
        "id": "h-UjENY_WRAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storage"
      ],
      "metadata": {
        "id": "aaRoFD7A-Ck0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model, 'models/moj_model_gpu.pth')\n",
        "\n",
        "loaded_model = torch.load('models/moj_model_gpu.pth')\n",
        "print(model)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'models/moj_model_gpu_stateovi.pth')\n",
        "\n",
        "model_load = nn.Sequential(nn.Linear(input_size, hidden_size_1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_1, hidden_size_2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size_2, output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "model_load.load_state_dict(torch.load('models/moj_model_gpu_stateovi.pth'))\n",
        "model_load.to(device)\n",
        "\n",
        "print(model_load)\n",
        "# Dakle, pohrana je jako slična kada radimo s jednim GPU-om!\n",
        "# U slučaju korištenja više GPU-ova, slučaj je malo drugačiji jer se koristi DataParallel model\n",
        "# no to ćemo raditi na naprednim tehnikama treniranja."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "ehjSWbUj-KQF",
        "outputId": "b1cb8884-5fb6-445f-a9cb-88522bf34d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a23e59b120da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/moj_model_gpu.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/moj_model_gpu.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/moj_model_gpu.pth'"
          ]
        }
      ]
    }
  ]
}